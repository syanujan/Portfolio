##Start of Project
##Importing Basic Libraries
```python
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import seaborn as sns

#Importing Functions from Sklearn Library
```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

#Reading the Student Grades Dataset
```python
df_por = pd.read_csv('student-por.csv')

#Viewing the first few rows of data in the dataset
```python
df_por.head()

```python
#Look at the distribution of each attribute
sns.set_style("dark")
for i in range(len(df_por.columns)):
    fig, ax = plt.subplots()
    y=sns.histplot(df_por.iloc[:,i])  
    labels = [str(round((v/649)*100,0))+"%" if v else '' for v in y.containers[0].datavalues]
    y.bar_label(y.containers[0], labels=labels)
    plt.show()

## Outlier Identification
```python
# Create a method to calculate outliers
def find_outliers_iqr(df):
    q1=df.quantile(0.25)
    q3=df.quantile(0.75)
    iqr=q3-q1
    outliers = df[((df<(q1-1.5*iqr)) | (df>(q3+1.5*iqr)))]
    return outliers
```


```python
# Calling the outlier method to find outlier in 'age' column
find_outliers_iqr(df_por['age'])
```


```python
df_por.iloc[[279]]
```


```python
#Draw a boxplot to visually identify the outliers in age column
plt.figure(figsize=(8,3))
sns.boxplot(x=df_por["age"], color='yellow')
plt.title("Age Distribution")
plt.xlabel("Age");
```


```python
plt.figure(figsize=(10,7));
sns.set_style('whitegrid')
ax = sns.barplot(data=df_por, x='age', y=df_por['G3']);
ax.set_title('Age v/s Grades');
ax.set_xlabel('Age');
ax.set_ylabel('G3 Grades');
```


```python
plt.figure(figsize=(10,8))
sns.countplot(x=df_por['sex'],hue=df_por['age']);
plt.title('Age v/s Gender Distribution')
```

## Correlation Heat Map

### Creating Dummy Variables


```python
df_por.info()
```


```python
# Categorical variables with only two levels: converting to one binary dummy

binary_list = ['school', 'sex','address', 'famsize', 'Pstatus', 'schoolsup', 'famsup', 
               'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic']

df_por_reg = df_por

for column in binary_list:
    df_por_reg[column]=df_por[column].astype("category").cat.codes

df_por_reg.info()
```


```python
# Categorical variables with more than two levels: converting to multiple binary dummies

cat_list = ['Mjob', 'Fjob', 'reason', 'guardian']

df_por_reg = pd.get_dummies(df_por_reg, columns=cat_list, drop_first=True)
df_por_reg.info()
```


```python
# add column of ones for regression intercept

df_por_reg['Eins'] = np.ones((len(df_por_reg), ))

df_por_reg.head()
```

### Correlation Heat Map with Dummy Variables


```python
#mask = np.triu(np.ones_like(df_por_reg.corr(method='spearman'),dtype=bool))

plt.figure(figsize=(12,10))
ax = sns.heatmap(df_por_reg.corr(method='spearman'), cmap="seismic", annot=False, linewidths=.5, cbar_kws={"label": "Spearman's ρ"}, vmin=-1, vmax=1);  #,mask=mask
ax.set_title("Correlation Heat Map");


```


```python
# focus on parents

df_por_parents = df_por_reg.loc[:,'Medu':'Fedu'].merge(right = df_por_reg.loc[:,'Mjob_health':'Fjob_teacher'], left_index=True, right_index=True)

#mask = np.triu(np.ones_like(df_por_parents.corr(method='spearman'),dtype=bool))

plt.figure(figsize=(12,10))
ax = sns.heatmap(df_por_parents.corr(method='spearman'), cmap="seismic", annot=False, linewidths=.5, cbar_kws={"label": "Spearman's ρ"}, vmin=-1, vmax=1);  #,mask=mask
ax.set_title("Correlation Heat Map - Parents");
```

## Exploring Average Pass Rate by Factor



```python
col_list1 = list(df_por["G3"])

GradeGroup = []

length = (len(col_list1))
for i in range(length):
    if 0 <= (col_list1[i]) <= 10: #below 50% average
        GradeGroup.append(1)
    elif 11 <= (col_list1[i]) <= 20: #above 50% average 
        GradeGroup.append(2)
    else:
        GradeGroup.append(0)
df_por['GradeGroup'] = GradeGroup

print("% of Students that Passed: ",len(df_por.query('GradeGroup == 2')) / len(df_por.query('GradeGroup')))
```


```python
#higher - wants to take higher education (binary: yes or no) 

print("% of Students that passed with intentions of higher education: ",len(df_por.query('higher==0 and GradeGroup==2')) / len(df_por.query('higher==0')))
print("% of Students that passed with intentions of higher education: ",len(df_por.query('higher==1 and GradeGroup==2')) / len(df_por.query('higher==1')))
```


```python
#failures - number of past class failures (numeric: n if 1<=n<3, else 4)

print("% of Students that Passed with no failed classes: ",len(df_por.query('failures==0 and GradeGroup==2')) / len(df_por.query('GradeGroup==2')))
```


```python
#school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)

print("% of Students from Gabriel Pereira that passed: ",len(df_por.query('school==0 and GradeGroup==2')) / len(df_por.query('school==0 ')))
print("% of Students from Mousinho da Silveira that passed: ",len(df_por.query('school==1 and GradeGroup==2')) / len(df_por.query('school==1')))
```


```python
#romantic - with a romantic relationship (binary: yes or no)

print("% of Students that Passed while dating: ",len(df_por.query('romantic==0 and GradeGroup==2')) / len(df_por.query('romantic==0')))
print("% of Students that Passed not dating: ",len(df_por.query('romantic==1 and GradeGroup==2')) / len(df_por.query('romantic==1')))
```


```python
#schoolsup - extra educational support (binary: yes or no)

print("% of Students that Passed with Extra School Support: ",len(df_por.query('schoolsup==0 and GradeGroup==2')) / len(df_por.query('schoolsup==0')))
print("% of Students that Passed with no Extra School Support: ",len(df_por.query('schoolsup==1 and GradeGroup==2')) / len(df_por.query('schoolsup==1')))
```


```python
#health - 3 and over is good health, 2 and under is bad health
col_list2 = list(df_por["health"])

HealthGroup = []

length = (len(col_list2))
for i in range(length):
    if 0 <= (col_list2[i]) <= 2: #bad health status
        HealthGroup.append(1)
    elif 3 <= (col_list2[i]) <= 5: #average and above health status
        HealthGroup.append(2)
    else:
        HealthGroup.append(0)
        
df_por['HealthGroup'] = HealthGroup

print("% of Students that Passed With Good Health: ",len(df_por.query('HealthGroup == 2 and GradeGroup==2')) / len(df_por.query('HealthGroup==2')))
print("% of Students that Passed With Bad Health: ",len(df_por.query('HealthGroup == 1 and GradeGroup==2')) / len(df_por.query('HealthGroup==1')))
```


```python
#age - student's age (numeric: from 15 to 22) 

#out of total pop
print("% of Students that Passed Age 15: ",len(df_por.query('age==15 and GradeGroup==2')) / len(df_por.query('age==15')))
print("% of Students that Passed Age 16: ",len(df_por.query('age==16 and GradeGroup==2')) / len(df_por.query('age==16')))
print("% of Students that Passed Age 17: ",len(df_por.query('age==17 and GradeGroup==2')) / len(df_por.query('age==17')))
print("% of Students that Passed Age 18: ",len(df_por.query('age==18 and GradeGroup==2')) / len(df_por.query('age==18')))
print("% of Students that Passed Age 19: ",len(df_por.query('age==19 and GradeGroup==2')) / len(df_por.query('age==19')))
print("% of Students that Passed Age 20: ",len(df_por.query('age==20 and GradeGroup==2')) / len(df_por.query('age==20')))
print("% of Students that Passed Age 21: ",len(df_por.query('age==21 and GradeGroup==2')) / len(df_por.query('age==21')))
print("% of Students that Passed Age 22: ",len(df_por.query('age==22 and GradeGroup==2')) / len(df_por.query('age==22')))
```


```python
#sex - student's sex (binary: '0' - female or '1' - male) 

print("% of Female Students that Passed: ",len(df_por.query('sex==0 and GradeGroup==2')) / len(df_por.query('sex==0')))
print("% of Male Students that Passed: ",len(df_por.query('sex==1 and GradeGroup==2')) / len(df_por.query('sex==1')))
```


```python
#studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)
col_list2 = list(df_por["studytime"])

StudyTimeGroup = []

length = (len(col_list2))
for i in range(length):
    if 0 <= (col_list2[i]) < 2: 
        StudyTimeGroup.append(1)
    elif 2 <= (col_list2[i]) <= 5: 
        StudyTimeGroup.append(2)
    elif 5 <= (col_list2[i]) <= 10: #no occurances of this
        StudyTimeGroup.append(3)
    elif (col_list2[i]) > 10:  #no occurances of this
        StudyTimeGroup.append(4)
    else:
        StudyTimeGroup.append(0)
        
df_por['StudyTimeGroup'] = StudyTimeGroup


print("% of Students that Passed w/ less than 2 hours of studying out of total pass: ",len(df_por.query('StudyTimeGroup == 1 and GradeGroup==2')) / len(df_por.query('StudyTimeGroup == 1')))
print("% of Students that Passed w/ 2-5 hours of studying out of total pass: ",len(df_por.query('StudyTimeGroup == 2 and GradeGroup==2')) / len(df_por.query('StudyTimeGroup == 2')))

```

## Bar Plots


```python
#Grades based on Daily Alcohol consumption
df_por.pivot_table(columns='Dalc', values=('G1','G2','G3'))
```


```python
# Plotting bar graph to visualize the impact of Dalc on grades
matplotlib.rc("figure", figsize=(15,5))
df_por.pivot_table(columns='Dalc', values=('G1','G2','G3')).plot(kind='bar')
plt.title("Weekday Alcohol consumption v/s Grades")
```


```python
#Grades based on weekly alcohol consumption
df_por.pivot_table(columns='Walc', values=('G1','G2','G3'))
```


```python
# Plotting bar graph to visualize the impact of Walc on grades
matplotlib.rc("figure", figsize=(15,5))
df_por.pivot_table(columns='Walc', values=('G1','G2','G3')).plot(kind='bar')
plt.title("Weekend Alcohol consumption v/s Grades")
```


```python
#Grades based on gender
df_por.pivot_table(columns='sex', values=('G1','G2','G3'))
```


```python
# Plotting bar graph to visualize the impact of sex on grades
df_por.pivot_table(columns='sex', values=('G1','G2','G3')).plot(kind='bar')
```


```python
df_g1 = df_por['G1'].value_counts().sort_index()
df_g2 = df_por['G2'].value_counts().sort_index()
df_g3 = df_por['G3'].value_counts().sort_index()
display(df_g3.head())
```


```python
plt.figure(figsize=(20,10))
ax = df_g3.plot(kind='bar')
ax.set_xlabel('G3 grades')
ax.set_ylabel('Count of students')
ax.set_title("Student's G3 grades")
ax.plot()
```


```python
#G1 and G2 relation
sns.set_style('darkgrid')
plt.title("Relation between G1 and G2")
sns.barplot(x="G1",y="G2",data=df_por)
plt.show()
```


```python
#G2 and G3 relation
sns.set_style('darkgrid')
plt.title("Relation between G2 and G3")
sns.barplot(x="G2",y="G3",data=df_por)
plt.show()
```


```python
#alcohol consumption based on sex
sns.set_style('darkgrid')
sns.barplot(x = "sex", y = "Dalc", ci=None, color='#69b3a2', data = df_por)
plt.show()
```


```python
#G2 and G3 relation
sns.set_style('darkgrid')
sns.barplot(x="G2",y="G3",data=df_por)
plt.show()
```


```python
agesexfail=pd.crosstab(index=df_por["age"], columns=df_por["sex"], values=df_por["failures"], aggfunc="mean").round(2)
agesexfail
```


```python
g1=agesexfail.plot(kind="bar")
g1.set_ylabel("failures")
```


```python
higher1=pd.crosstab(index=df_por["higher"], columns=df_por["sex"], values=df_por["G3"], aggfunc="mean").round(2)
higher1
```


```python
g2=higher1.plot(kind="bar")
g2.set_ylabel("")
```


```python
AgeG3=pd.crosstab(index=df_por["age"], columns=df_por["sex"], values=df_por["G3"], aggfunc="mean").round(2)
AgeG3

```


```python
g3=AgeG3.plot(kind="bar")
g3.set_ylabel("Avg G3")

```

## Pair Plot


```python
sns.pairplot(df_por)

```


```python
sns.pairplot(df_por.loc[:,"G1":"G3"])
```

## Regression


### Train/Test Split


```python
df_por_reg.info()
```


```python
# omits G1, G2, G3
X = df_por_reg.loc[:,'school':'absences'].merge(right = df_por_reg.loc[:,'Mjob_health':'Eins'], left_index=True, right_index=True)
y = df_por_reg.loc[:,'G3']    # G3 only

print(X.shape)
print(y.shape)
```


```python
test_size = 0.25

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state = 12)    #set state for reproducible outcome

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)
```


```python
# second data split including G1, G2
X1 = df_por_reg.loc[:,'school':'G2'].merge(right = df_por_reg.loc[:,'Mjob_health':'Eins'], left_index=True, right_index=True)
y1 = df_por_reg.loc[:,'G3']    # G3 only

print(X1.shape)
print(y1.shape)

X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=test_size, random_state = 12)    #set state for reproducible outcome

print(X1_train.shape)
print(X1_test.shape)
print(y1_train.shape)
print(y1_test.shape)
```


```python
# setting up df to capture results
labels = [['Linear','RF'],['No Midterm', 'With Midterm'], ['Outlier Removed', 'Outlier Included']]
index = pd.MultiIndex.from_product(labels, names=['Model Type', 'Midterm Status', 'Outlier Status'])

df_results = pd.DataFrame(np.reshape(np.zeros(16),(8,2)), index=index, columns=['MSE','R^2'])
df_results
```

### Linear Regression


```python
linear_regr = LinearRegression()
linear_regr.fit(X_train, y_train)

y_pred = linear_regr.predict(X_test) 

print("MSE:", np.sqrt(mean_squared_error(y_test, y_pred)))
print("R²:", r2_score(y_test, y_pred))

df_results.loc[('Linear', 'No Midterm', 'Outlier Included'), 'MSE'] = np.sqrt(mean_squared_error(y_test, y_pred))
df_results.loc[('Linear', 'No Midterm', 'Outlier Included'), 'R^2'] = r2_score(y_test, y_pred)

#print(df_results)
```


```python
y_test.std()
```


```python
# using data with G1, G2

linear_regr1 = LinearRegression()
linear_regr1.fit(X1_train, y1_train)

y1_pred = linear_regr1.predict(X1_test) 

print("RMSE:", np.sqrt(mean_squared_error(y1_test, y1_pred)))
print("R²:", r2_score(y1_test, y1_pred))


df_results.loc[('Linear', 'With Midterm', 'Outlier Included'), 'MSE'] = np.sqrt(mean_squared_error(y1_test, y1_pred))
df_results.loc[('Linear', 'With Midterm', 'Outlier Included'), 'R^2'] = r2_score(y1_test, y1_pred)
```

### Random Forest Regression


```python
rf_reg = RandomForestRegressor(n_estimators=100, n_jobs=-1)
rf_reg.fit(X_train, y_train)

y_pred = rf_reg.predict(X_test)

print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred))) #RMSE: root mean square error
print("R²:", r2_score(y_test, y_pred))

df_results.loc[('RF', 'No Midterm', 'Outlier Included'), 'MSE'] = np.sqrt(mean_squared_error(y_test, y_pred))
df_results.loc[('RF', 'No Midterm', 'Outlier Included'), 'R^2'] = r2_score(y_test, y_pred)
```


```python
y_test.std()
```


```python
# using data with G1, G2

rf_reg1 = RandomForestRegressor(n_estimators=100, n_jobs=-1)
rf_reg1.fit(X1_train, y1_train)

y1_pred = rf_reg1.predict(X1_test)

print("RMSE:", np.sqrt(mean_squared_error(y1_test, y1_pred))) #RMSE: root mean square error
print("R²:", r2_score(y1_test, y1_pred))

df_results.loc[('RF', 'With Midterm', 'Outlier Included'), 'MSE'] = np.sqrt(mean_squared_error(y1_test, y1_pred))
df_results.loc[('RF', 'With Midterm', 'Outlier Included'), 'R^2'] = r2_score(y1_test, y1_pred)
```

### Outlier Removal

Test if removing age=22 improves the models


```python
df_por_out = df_por_reg[df_por_reg['age']<22]

df_por_out.info()
# one outlier removed
```


```python
# omits G1, G2, G3
X = df_por_out.loc[:,'school':'absences'].merge(right = df_por_out.loc[:,'Mjob_health':'Eins'], left_index=True, right_index=True)
y = df_por_out.loc[:,'G3']    # G3 only

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state = 12)    #set state for reproducible outcome
```


```python
# second data split including G1, G2
X1 = df_por_out.loc[:,'school':'G2'].merge(right = df_por_out.loc[:,'Mjob_health':'Eins'], left_index=True, right_index=True)
y1 = df_por_out.loc[:,'G3']    # G3 only

print(X1.shape)
print(y1.shape)

X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=test_size, random_state = 12)    #set state for reproducible outcome
```


```python
# linear regression

# without midterm grades 
linear_regr = LinearRegression()
linear_regr.fit(X_train, y_train)

y_pred = linear_regr.predict(X_test) 

print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))
print("R²:", r2_score(y_test, y_pred))

df_results.loc[('Linear', 'No Midterm', 'Outlier Removed'), 'MSE'] = np.sqrt(mean_squared_error(y_test, y_pred))
df_results.loc[('Linear', 'No Midterm', 'Outlier Removed'), 'R^2'] = r2_score(y_test, y_pred)

# with G1, G2

linear_regr1 = LinearRegression()
linear_regr1.fit(X1_train, y1_train)

y1_pred = linear_regr1.predict(X1_test) 

print("RMSE:", np.sqrt(mean_squared_error(y1_test, y1_pred)))
print("R²:", r2_score(y1_test, y1_pred))

df_results.loc[('Linear', 'With Midterm', 'Outlier Removed'), 'MSE'] = np.sqrt(mean_squared_error(y1_test, y1_pred))
df_results.loc[('Linear', 'With Midterm', 'Outlier Removed'), 'R^2'] = r2_score(y1_test, y1_pred)
```


```python
# RF regression

# without midterm grades
rf_reg = RandomForestRegressor(n_estimators=100, n_jobs=-1)
rf_reg.fit(X_train, y_train)

y_pred = rf_reg.predict(X_test)

print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred))) #RMSE: root mean square error
print("R²:", r2_score(y_test, y_pred))

df_results.loc[('RF', 'No Midterm', 'Outlier Removed'), 'MSE'] = np.sqrt(mean_squared_error(y_test, y_pred))
df_results.loc[('RF', 'No Midterm', 'Outlier Removed'), 'R^2'] = r2_score(y_test, y_pred)


# with G1, G2

rf_reg1 = RandomForestRegressor(n_estimators=100, n_jobs=-1)
rf_reg1.fit(X1_train, y1_train)

y1_pred = rf_reg1.predict(X1_test)

print("RMSE:", np.sqrt(mean_squared_error(y1_test, y1_pred))) #RMSE: root mean square error
print("R²:", r2_score(y1_test, y1_pred))

df_results.loc[('RF', 'With Midterm', 'Outlier Removed'), 'MSE'] = np.sqrt(mean_squared_error(y1_test, y1_pred))
df_results.loc[('RF', 'With Midterm', 'Outlier Removed'), 'R^2'] = r2_score(y1_test, y1_pred)
```

### Results and Best Model


```python
df_results
```


```python
# for RF model with outlier removed and without midterm grades

# print(rf_reg.feature_importances_)
# print(X.columns)
rf_imp = pd.DataFrame(X.columns).merge(pd.DataFrame(rf_reg.feature_importances_),left_index=True,right_index=True)
rf_imp.rename(columns={'0_x':'Feature','0_y':'Importance'}, inplace=True)
rf_imp.sort_values(by='Importance', axis=0, ascending=False, inplace=True)
rf_imp

